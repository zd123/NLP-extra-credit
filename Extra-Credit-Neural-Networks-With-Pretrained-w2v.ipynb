{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d7c833d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-19 16:57:39.280576: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IsSpam</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>key issues going forwarda year end reviews rep...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>congrats contratulations the execution the cen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>key issues going forwardall under control set...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>epmi files protest entergy transcoattached our...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>california power please contact kristin walsh ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   IsSpam                                               Text\n",
       "0       0  key issues going forwarda year end reviews rep...\n",
       "1       0  congrats contratulations the execution the cen...\n",
       "2       0   key issues going forwardall under control set...\n",
       "3       0  epmi files protest entergy transcoattached our...\n",
       "4       0  california power please contact kristin walsh ..."
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv1D, MaxPooling1D, GlobalMaxPooling1D\n",
    "from keras.layers import Dense, Input, Flatten\n",
    "\n",
    "from keras.utils import pad_sequences\n",
    "from keras.utils.np_utils import to_categorical\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "df = pd.read_csv('data/ham-vs-spam.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "93b9ac27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"4\" halign=\"left\">Text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>unique</th>\n",
       "      <th>top</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IsSpam</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>499</td>\n",
       "      <td>499</td>\n",
       "      <td>key issues going forwarda year end reviews rep...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>500</td>\n",
       "      <td>500</td>\n",
       "      <td>take the reinsbecomeyour employer substantial ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Text                                                               \n",
       "       count unique                                                top freq\n",
       "IsSpam                                                                     \n",
       "0        499    499  key issues going forwarda year end reviews rep...    1\n",
       "1        500    500  take the reinsbecomeyour employer substantial ...    1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop_duplicates()\n",
    "df.groupby('IsSpam').describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d04676a5",
   "metadata": {},
   "source": [
    "# Using pretrained word2vec vectors\n",
    "\n",
    "You load them from the file you downloaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "38155d57",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "400000it [00:15, 25002.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Found 400000 word vectors.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# https://www.kaggle.com/datasets/danielwillgeorge/glove6b100dtxt\n",
    "\n",
    "embeddings_index = {}\n",
    "\n",
    "path = 'models/'\n",
    "\n",
    "f = open(path+'glove.6B.100d.txt')\n",
    "\n",
    "for line in tqdm(f):\n",
    "    values = line.split(' ')\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "\n",
    "print ()\n",
    "print ('Found %s word vectors.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "179a2aef",
   "metadata": {},
   "source": [
    "### This is what the file glove.6B.100d.txt looks like:\n",
    "```\n",
    "the -0.038194 -0.24487 0.72812...\n",
    "of -0.1529 -0.24279 0.89837...\n",
    "and -0.071953 0.23127 0.023731...\n",
    "in 0.085703 -0.22201 0.16569...\n",
    "a -0.27086 0.044006 -0.02026...\n",
    "for -0.14401 0.32554 0.14257...\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "50c5a963",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "400000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(embeddings_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b5e516e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['Text']\n",
    "y = df['IsSpam']\n",
    "\n",
    "X_text = X\n",
    "\n",
    "max_words = 20000\n",
    "MAX_SEQUENCE_LENGTH = 500\n",
    "\n",
    "tokenizer = Tokenizer(num_words=max_words)\n",
    "\n",
    "tokenizer.fit_on_texts(X)\n",
    "\n",
    "sequences = tokenizer.texts_to_sequences(X)\n",
    "\n",
    "X = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "\n",
    "y = to_categorical( np.array(y) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d9a00970",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 0.], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b524f05b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "word_index = tokenizer.word_index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "83d3f3d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26188, 100)\n",
      "[-0.038194   -0.24487001  0.72812003 -0.39961001  0.083172    0.043953\n",
      " -0.39140999  0.3344     -0.57545     0.087459    0.28786999 -0.06731\n",
      "  0.30906001 -0.26383999 -0.13231    -0.20757     0.33395001 -0.33848\n",
      " -0.31742999 -0.48335999  0.1464     -0.37303999  0.34577     0.052041\n",
      "  0.44946    -0.46970999  0.02628    -0.54154998 -0.15518001 -0.14106999\n",
      " -0.039722    0.28277001  0.14393     0.23464    -0.31020999  0.086173\n",
      "  0.20397     0.52623999  0.17163999 -0.082378   -0.71787    -0.41531\n",
      "  0.20334999 -0.12763     0.41367     0.55186999  0.57907999 -0.33476999\n",
      " -0.36559001 -0.54856998 -0.062892    0.26583999  0.30204999  0.99774998\n",
      " -0.80480999 -3.0243001   0.01254    -0.36941999  2.21670008  0.72201002\n",
      " -0.24978     0.92136002  0.034514    0.46744999  1.10790002 -0.19358\n",
      " -0.074575    0.23353    -0.052062   -0.22044     0.057162   -0.15806\n",
      " -0.30798    -0.41624999  0.37972     0.15006    -0.53211999 -0.20550001\n",
      " -1.25259995  0.071624    0.70564997  0.49744001 -0.42063001  0.26148\n",
      " -1.53799999 -0.30223    -0.073438   -0.28312001  0.37103999 -0.25217\n",
      "  0.016215   -0.017099   -0.38984001  0.87423998 -0.72569001 -0.51058\n",
      " -0.52028    -0.1459      0.82779998  0.27061999]\n"
     ]
    }
   ],
   "source": [
    "EMBEDDING_DIM = 100\n",
    "\n",
    "embedding_matrix = np.random.random( (len(word_index) + 1, EMBEDDING_DIM))\n",
    "for word, i in word_index.items():\n",
    "  embedding_vector = embeddings_index.get(word)\n",
    "  if embedding_vector is not None:\n",
    "#     words not found in embedding index will be random-values.\n",
    "    embedding_matrix[i] = embedding_vector\n",
    "\n",
    "print (embedding_matrix.shape)\n",
    "\n",
    "print ( embedding_matrix[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "51f6f098",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_3 (Embedding)     (None, 500, 100)          2618800   \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 50000)             0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 128)               6400128   \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 2)                 258       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9,019,186\n",
      "Trainable params: 6,400,386\n",
      "Non-trainable params: 2,618,800\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create your Neural Network\n",
    "\n",
    "embedding_layer = Embedding( \n",
    "    len(word_index)+1, \n",
    "    100, \n",
    "    weights=[embedding_matrix], \n",
    "    input_length=MAX_SEQUENCE_LENGTH, \n",
    "    trainable=False)\n",
    "\n",
    "\n",
    "model = Sequential() \n",
    "\n",
    "model.add(  embedding_layer  ) \n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(2, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy']) \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4d6789b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "7/7 [==============================] - 1s 94ms/step - loss: 11.8094 - accuracy: 0.5532 - val_loss: 24.1484 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "7/7 [==============================] - 0s 68ms/step - loss: 3.9713 - accuracy: 0.6145 - val_loss: 0.1941 - val_accuracy: 0.9650\n",
      "Epoch 3/10\n",
      "7/7 [==============================] - 0s 68ms/step - loss: 1.4144 - accuracy: 0.6395 - val_loss: 2.5373 - val_accuracy: 0.0550\n",
      "Epoch 4/10\n",
      "7/7 [==============================] - 0s 65ms/step - loss: 0.7209 - accuracy: 0.7284 - val_loss: 1.1231 - val_accuracy: 0.2100\n",
      "Epoch 5/10\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 0.5185 - accuracy: 0.7710 - val_loss: 0.5239 - val_accuracy: 0.9150\n",
      "Epoch 6/10\n",
      "7/7 [==============================] - 0s 68ms/step - loss: 0.4368 - accuracy: 0.8486 - val_loss: 1.2864 - val_accuracy: 0.2000\n",
      "Epoch 7/10\n",
      "7/7 [==============================] - 0s 73ms/step - loss: 0.4081 - accuracy: 0.8548 - val_loss: 0.7793 - val_accuracy: 0.6200\n",
      "Epoch 8/10\n",
      "7/7 [==============================] - 0s 70ms/step - loss: 0.3389 - accuracy: 0.8786 - val_loss: 0.5425 - val_accuracy: 0.8600\n",
      "Epoch 9/10\n",
      "7/7 [==============================] - 1s 71ms/step - loss: 0.3107 - accuracy: 0.9174 - val_loss: 1.1451 - val_accuracy: 0.2600\n",
      "Epoch 10/10\n",
      "7/7 [==============================] - 0s 67ms/step - loss: 0.2877 - accuracy: 0.9074 - val_loss: 0.5675 - val_accuracy: 0.8450\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X, y,validation_split=0.2, epochs=10, batch_size=128)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "23746bb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_5 (Embedding)     (None, 500, 100)          2618800   \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 496, 233)          116733    \n",
      "                                                                 \n",
      " conv1d_2 (Conv1D)           (None, 492, 144)          167904    \n",
      "                                                                 \n",
      " max_pooling1d_1 (MaxPooling  (None, 246, 144)         0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " flatten_4 (Flatten)         (None, 35424)             0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 2)                 70850     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,974,287\n",
      "Trainable params: 355,487\n",
      "Non-trainable params: 2,618,800\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# now create a CNN Neural network\n",
    "\n",
    "embedding_layer = Embedding(len(word_index)+1, \n",
    "                            100, \n",
    "                            weights=[embedding_matrix], \n",
    "                            input_length=MAX_SEQUENCE_LENGTH, \n",
    "                            trainable=False)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(embedding_layer)\n",
    "model.add(Conv1D(filters=233, kernel_size=5, activation='relu'))\n",
    "model.add(Conv1D(filters=144, kernel_size=5, activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(2, activation='sigmoid'))\n",
    "print(model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ca3be744",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/7\n",
      "7/7 [==============================] - 5s 625ms/step - loss: 0.0967 - accuracy: 0.9662 - val_loss: 0.6477 - val_accuracy: 0.8700\n",
      "Epoch 2/7\n",
      "7/7 [==============================] - 5s 732ms/step - loss: 0.0361 - accuracy: 0.9887 - val_loss: 0.7579 - val_accuracy: 0.8250\n",
      "Epoch 3/7\n",
      "7/7 [==============================] - 6s 831ms/step - loss: 0.0255 - accuracy: 0.9900 - val_loss: 0.4908 - val_accuracy: 0.8550\n",
      "Epoch 4/7\n",
      "7/7 [==============================] - 6s 884ms/step - loss: 0.0229 - accuracy: 0.9912 - val_loss: 0.4271 - val_accuracy: 0.9000\n",
      "Epoch 5/7\n",
      "7/7 [==============================] - 6s 905ms/step - loss: 0.0167 - accuracy: 0.9950 - val_loss: 0.3722 - val_accuracy: 0.9100\n",
      "Epoch 6/7\n",
      "7/7 [==============================] - 6s 786ms/step - loss: 0.0132 - accuracy: 0.9975 - val_loss: 0.3757 - val_accuracy: 0.8950\n",
      "Epoch 7/7\n",
      "7/7 [==============================] - 5s 758ms/step - loss: 0.0106 - accuracy: 0.9962 - val_loss: 0.5103 - val_accuracy: 0.8800\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X, y,validation_split=0.2, epochs=7, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c3f9071",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4bab01eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why pay more for expensive meds when you can order them online and save $$$?\n",
      "1/1 [==============================] - 0s 153ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.00278071, 0.997074  ]], dtype=float32)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_text = 'Why pay more for expensive meds when you can order them online and save $$$?'\n",
    "\n",
    "print(cleaned_text)\n",
    "\n",
    "sequence = tokenizer.texts_to_sequences([cleaned_text])\n",
    "\n",
    "padded_sequence = pad_sequences(sequence, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "model.predict(padded_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "44adb109",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hey jon, I cannot make the meeting tomorrow. can you please send me a time that you can meet on tuesday. thanks, harry\n",
      "1/1 [==============================] - 0s 25ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_text = 'hey jon, I cannot make the meeting tomorrow. can you please send me a time that you can meet on tuesday. thanks, harry'\n",
    "print(cleaned_text)\n",
    "\n",
    "sequence = tokenizer.texts_to_sequences([cleaned_text])\n",
    "padded_sequence = pad_sequences(sequence, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "model.predict(padded_sequence).round(3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "940f724c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Can you attend a code review on Tuesday? Need to make sure the logic is rock solid.\n",
      "1/1 [==============================] - 0s 34ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.9985674 , 0.00155001]], dtype=float32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_text = 'Can you attend a code review on Tuesday? Need to make sure the logic is rock solid.'\n",
    "print(cleaned_text)\n",
    "\n",
    "sequence = tokenizer.texts_to_sequences([cleaned_text])\n",
    "padded_sequence = pad_sequences(sequence, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "model.predict(padded_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e49064bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "from daniel mutadei truely solicite your assistance for business proposal dear friend absolute confidence ensure this urgent and important businees proposal with you greatly optimistic forward you this note regards your assistance enable execute venture mutual benefit with you name daniel mutade senior employee with the central bank zimbabwe during the last national election held president robert mugabe and colleagues worked out twenty million united states dollars over invoiced and inflated payment for election materials and the fund now deposited with security company europe for safe keeping are not sure the future our country zimbabwe due the cry more sanctions world leaders and around the world result the brutal take over white farmers land and residents zimbabwe the mugabe administration colleagues and are now seeking secure and invest this funds wisely abroad currently europe short visit and involvement this transaction shall kept secret since our civil service code conduct forbids have any private account and financial dealings this magnitude for this reason need the assistance foreign company person push this money into their his account your share assisting successfully put intoyour account this moneywill the total sum while will for colleagues and and has been mapped out for any expenses that may incured both parties during the cause transferring the funds into your nominated bank account will refrain from giving out more operational details until urgentlyreceive your reply interest since time the essence this transaction however need inform you that this transaction risk free because have done our homework carefully ensure the smoothness and realization this transaction please you consider this business necessary reply soon possible for more details this transaction will usher into greater benefits within shortest possible time could you please send your reply dmutade mail dave com please include your telephone and fax numbers when replying this business proposal truely yours daniel mutadeexpn com mail http expnmail com\n",
      "1/1 [==============================] - 0s 26ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.001, 1.   ]], dtype=float32)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_text = df[df.IsSpam==1]['Text'].iloc[0:5].values[4]\n",
    "print(cleaned_text)\n",
    "\n",
    "# cleaned_text = 'important news for usavity customers dear cheapsoft customer name annie kincaid and work cheapsoft llc you are important you spend your money and time cheapsoft and want let you know that have finished update our programs store want remind you that are offering now more than popularsoftware for low price with your personal customer discount please spend few moments yours precious time check our updated softwarestore http www dutyfreesoft all infowith regards customer service department annie kincaid'\n",
    "sequence = tokenizer.texts_to_sequences([cleaned_text])\n",
    "\n",
    "padded_sequence = pad_sequences(sequence, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "\n",
    "model.predict(padded_sequence).round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60393752",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
